input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
target_text = tolower(gsub("[[:space:]]|[.]|[,]", "", target_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,target_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,target_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_target_length = expand.grid(str_length(input_text),str_length(target_text))
input_target_length = input_target_length %>% mutate(sum=Var1+Var2)
input_target_length_matrix = matrix(input_target_length$sum,length(input_text),length(target_text))
df_return_scale = (input_target_length_matrix-dist.input_text)*100/input_target_length_matrix
df_return_reshape = matrix(df_return_scale,length(input_text)*length(target_text),1)
# scaling the distance into 0 to 100
df_return = data.frame(df_return,df_return_reshape) %>%
rename(similarity_score = df_return_reshape)
df_output = df_return %>% mutate(similarity_score=round(similarity_score,2))
df_output = data.frame(df_input_original,df_output) %>% select('input_text_original','target_text_original','similarity_score') %>%
rename(
input_text = input_text_original,
target_text = target_text_original) %>%
filter(similarity_score>=score)
# output
return(df_output)
}
df = text_similarity_score(unique(data_file$Country),c("Germany","South Korea"),ignore_case = FALSE,score=80)
View(df)
df = text_similarity_score(unique(data_file$Country),c("Germany","South Korea"),ignore_case = FALSE)
View(df)
df = text_similarity_score(unique(data_file$Country),c("Germany","South Korea"),ignore_case = FALSE,score=80)
View(df)
text_similarity_score = function(input_text,target_text,space=FALSE,ignore_case=TRUE,score=0,limit=length(input_text)){
# keeping the original input intact
df_input_original = data.frame(expand.grid(input_text_original,target_text_original)) %>%
rename(
input_text_original=Var1,
target_text_original=Var2) %>%
mutate(across(where(is.factor), as.character))
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
target_text = tolower(gsub("[[:space:]]|[.]|[,]", "", target_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,target_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,target_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_target_length = expand.grid(str_length(input_text),str_length(target_text))
input_target_length = input_target_length %>% mutate(sum=Var1+Var2)
input_target_length_matrix = matrix(input_target_length$sum,length(input_text),length(target_text))
df_return_scale = (input_target_length_matrix-dist.input_text)*100/input_target_length_matrix
df_return_reshape = matrix(df_return_scale,length(input_text)*length(target_text),1)
# scaling the distance into 0 to 100
df_return = data.frame(df_return,df_return_reshape) %>%
rename(similarity_score = df_return_reshape)
df_output = df_return %>% mutate(similarity_score=round(similarity_score,2))
df_output = data.frame(df_input_original,df_output) %>% select('input_text_original','target_text_original','similarity_score') %>%
rename(
input_text = input_text_original,
target_text = target_text_original) %>%
filter(similarity_score>=score)
# output
return(df_output)
}
df = text_similarity_score(unique(data_file$Country),c("Germany","South Korea"),ignore_case = FALSE,score=80)
text_similarity_score = function(input_text,target_text,space=FALSE,ignore_case=TRUE,score=0,limit=length(input_text)){
# keeping the original input intact
df_input_original = data.frame(expand.grid(input_text,target_text)) %>%
rename(
input_text_original=Var1,
target_text_original=Var2) %>%
mutate(across(where(is.factor), as.character))
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
target_text = tolower(gsub("[[:space:]]|[.]|[,]", "", target_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,target_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,target_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_target_length = expand.grid(str_length(input_text),str_length(target_text))
input_target_length = input_target_length %>% mutate(sum=Var1+Var2)
input_target_length_matrix = matrix(input_target_length$sum,length(input_text),length(target_text))
df_return_scale = (input_target_length_matrix-dist.input_text)*100/input_target_length_matrix
df_return_reshape = matrix(df_return_scale,length(input_text)*length(target_text),1)
# scaling the distance into 0 to 100
df_return = data.frame(df_return,df_return_reshape) %>%
rename(similarity_score = df_return_reshape)
df_output = df_return %>% mutate(similarity_score=round(similarity_score,2))
df_output = data.frame(df_input_original,df_output) %>% select('input_text_original','target_text_original','similarity_score') %>%
rename(
input_text = input_text_original,
target_text = target_text_original) %>%
filter(similarity_score>=score)
# output
return(df_output)
}
#reading data
data_file = read.csv("pakistan_intellectual_capital.csv",header=TRUE)
df = text_similarity_score(unique(data_file$Country),c("Germany","South Korea"),ignore_case = FALSE,score=80)
View(df)
target_text
View(df)
head(data_file$Country)
data_new = data_file %>% left_join(df,by=c("Country","input_text"))
names(df)
data_new = data_file %>% left_join(df,by=c("Country"="input_text"))
View(data_new)
data_new$truth = data_new$Country %in% df$input_text
data_new$truth2 = which(data_new$Country %in% df$input_text)
data_new$truth2 = match(data_new$Country,df$input_text)
View(data_file)
View(data_new)
data_new$truth3 = df$target_text[match(data_new$Country,df$input_text)]
input_text = unique(data_file$Country)
install.packages("dbscan")
library(dbscan)
# keeping the original input intact
df_input_original = input_text
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
ignore_case = TRUE
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
View(dist.input_text)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
View(df_return)
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)*100/input_length_matrix
View(df_return_scale)
score=80
View(df_return_scale)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(scale.input_file.clean,eps = 0.15,minPts = 1)
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score,df_return_scale,0)
View(df_return_scale.clean)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.15,minPts = 1)
db.cluster
db.cluster$cluster
#assigning label to customer
output_file = as.data.frame(input_file_original)
# keeping the original input intact
input_text_original = input_text
#assigning label to customer
output_file = as.data.frame(input_file_original)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$label = db.cluster$cluster
View(output_file)
View(output_file)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.01,minPts = 1)
db.cluster
db.cluster$cluster
db.cluster$eps
db.cluster$minPts
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.000001,minPts = 1)
db.cluster
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
View(df_return_scale)
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
View(df_return_scale.clean)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.15,minPts = 1)
db.cluster
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$label = db.cluster$cluster
View(output_file)
db.cluster$cluster[1]
db.cluster$cluster
output_file$label = db.cluster$cluster
View(output_file)
output_file = output_file %>% arrange(label)
View(output_file)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(label) %>% rename(
input_text = input_text_original
)
View(output_file)
df_id = text_similarity_id(unique(data_file$Country))
text_similarity_id = function(input_text,space=FALSE,ignore_case=TRUE,score=80){
# keeping the original input intact
input_text_original = input_text
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.15,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(label) %>% rename(
input_text = input_text_original
)
# output
return(output_file)
}
input_text = unique(data_file$Country)
df_id = text_similarity_id(unique(data_file$Country))
text_similarity_id = function(input_text,space=FALSE,ignore_case=TRUE,score=80){
# keeping the original input intact
input_text_original = input_text
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = 0.15,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(id) %>% rename(
input_text = input_text_original
)
# output
return(output_file)
}
df_id = text_similarity_id(unique(data_file$Country))
View(df_id)
df = text_similarity_score(unique(data_file$Country),c("USA"),ignore_case = FALSE,score=0)
View(df)
df_id = text_similarity_id(unique(data_file$Country),score=75)
View(df_id)
df_id = text_similarity_id(unique(data_file$Country),score=75)
View(df_id)
text_similarity_id = function(input_text,space=FALSE,ignore_case=TRUE,score=80,eps=0.15){
# keeping the original input intact
input_text_original = input_text
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = eps,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(id) %>% rename(
input_text = input_text_original
)
# output
return(output_file)
}
#reading data
data_file = read.csv("pakistan_intellectual_capital.csv",header=TRUE)
df_id = text_similarity_id(unique(data_file$Country),score=75)
View(df_id)
score=80
eps=0.15
input_text = unique(data_file$Country)
score=75
# keeping the original input intact
input_text_original = input_text
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
ignore_case=TRUE
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
View(df_return_scale)
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
View(df_return_scale.clean)
View(input_length)
dataf = data.frame(input_text)
View(dataf)
df = text_similarity_score(unique(data_file$Country),c("Finland"),ignore_case = FALSE,score=0)
text_similarity_score = function(input_text,target_text,space=FALSE,ignore_case=TRUE,score=0,limit=length(input_text)){
# keeping the original input intact
df_input_original = data.frame(expand.grid(input_text,target_text)) %>%
rename(
input_text_original=Var1,
target_text_original=Var2) %>%
mutate(across(where(is.factor), as.character))
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
target_text = tolower(gsub("[[:space:]]|[.]|[,]", "", target_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,target_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,target_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_target_length = expand.grid(str_length(input_text),str_length(target_text))
input_target_length = input_target_length %>% mutate(sum=Var1+Var2)
input_target_length_matrix = matrix(input_target_length$sum,length(input_text),length(target_text))
df_return_scale = (input_target_length_matrix-dist.input_text)*100/input_target_length_matrix
df_return_reshape = matrix(df_return_scale,length(input_text)*length(target_text),1)
# scaling the distance into 0 to 100
df_return = data.frame(df_return,df_return_reshape) %>%
rename(similarity_score = df_return_reshape)
df_output = df_return %>% mutate(similarity_score=round(similarity_score,2))
df_output = data.frame(df_input_original,df_output) %>% select('input_text_original','target_text_original','similarity_score') %>%
rename(
input_text = input_text_original,
target_text = target_text_original) %>%
filter(similarity_score>=score)
# output
return(df_output)
}
df = text_similarity_score(unique(data_file$Country),c("Finland"),ignore_case = FALSE,score=0)
View(df)
df = text_similarity_score(unique(data_file$Country),c("USA"),ignore_case = FALSE,score=0)
View(df)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = eps,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
View(output_file)
text_similarity_id = function(input_text,space=FALSE,ignore_case=TRUE,score=75,eps=0.2){
# keeping the original input intact
input_text_original = input_text
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = eps,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(id) %>% rename(
input_text = input_text_original)
# output
return(output_file)
}
df_id = text_similarity_id(unique(data_file$Country),score=75)
View(df_id)
text_similarity_id = function(input_text,space=FALSE,ignore_case=TRUE,score=80,eps=0.15){
# keeping the original input intact
input_text_original = input_text
if (space==TRUE){
input_text =tolower(gsub("[[:space:]]|[.]|[,]", "", input_text))
}
#distance using Levenshtein
dist.input_text = adist(input_text,input_text, ignore.case=ignore_case)
# distance of original text
df_return = data.frame(expand.grid(input_text,input_text))%>%
rename(
input_text = Var1,
target_text = Var2) %>%
mutate(across(where(is.factor), as.character))
# distance of original text
# scaling distance name
input_length = expand.grid(str_length(input_text),str_length(input_text))
input_length = input_length %>% mutate(sum=Var1+Var2)
input_length_matrix = matrix(input_length$sum,length(input_text),length(input_text))
df_return_scale = (input_length_matrix-dist.input_text)/input_length_matrix
# take where the value >= score
df_return_scale.clean = ifelse(df_return_scale>=score/100,df_return_scale,0)
# labeling by clustering the end result using DBSCAN
db.cluster = dbscan(df_return_scale.clean,eps = eps,minPts = 1)
#assigning label to customer
output_file = as.data.frame(input_text_original)
output_file$id = db.cluster$cluster
output_file = output_file %>% arrange(id) %>% rename(
input_text = input_text_original)
# output
return(output_file)
}
df_id = text_similarity_id(unique(data_file$Country),score=75,eps=0.25)
View(df_id)
df_id = text_similarity_id(unique(data_file$Country),score=75,eps=0.3)
View(df_id)
df_id = text_similarity_id(unique(data_file$Country),score=75,eps=0.5)
library(devtools)
library(roxygen2)
create("similaRText")
setwd("D:/R Package Project/R Package Production")
create("similaRText")
R --version
R.Version()
getwd()
data_sample = read.csv("pakistan_intellectual_capital.csv")
use_data(data_sample,pkg="similaRText")
dir()
cd similaRText
setwd(./similaRText)
setwd("similaRText"")
""
setwd("similaRText")
use_data(data_sample,pkg="similaRText")
data_sample
use_data(data_sample,pkg="similaRText",overwrite = TRUE)
data_sample_pakistan = read.csv("pakistan_intellectual_capital.csv")
data_sample_pakistan = data_sample
use_data(data_sample_pakistan,pkg="similaRText",overwrite = TRUE)
use_data(data_sample,overwrite = TRUE)
use_vignette("Getting_Text_Similarity_Score_with_similaRText")
str(data_sample)
View(data_sample)
names(data_sample)
document()
rm(list = c("text_similarity_id", "text_similarity_score"))
document()
dir()
dir("man")
help(similaRText)
help(data_sample.Rd)
help(text_similarity_id.Rd)
help(text_similarity_score.Rd)
devtools::install_github(dessyamirudin/similaRText)
devtools::install_github("dessyamirudin/similaRText")
devtools::install_github("dessyamirudin/similaRText")
